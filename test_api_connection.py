#!/usr/bin/env python3
"""
OpenAI APIç–é€šãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- APIæ¥ç¶šã®ç¢ºèª
- å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ç¢ºèª
"""

import os
import sys
import asyncio
import json
import time
from datetime import datetime
from typing import Dict, Any, Optional
import logging

# OpenAI imports
from openai import AsyncOpenAI, OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class APIConnectionTester:
    """OpenAI APIæ¥ç¶šãƒ†ã‚¹ã‚¿ãƒ¼"""
    
    def __init__(self):
        self.api_key = os.environ.get('OPENAI_API_KEY')
        self.test_results = {}
        
    def check_api_key(self) -> bool:
        """APIã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª"""
        logger.info("=" * 60)
        logger.info("ğŸ”‘ APIã‚­ãƒ¼ç¢ºèª")
        logger.info("=" * 60)
        
        if not self.api_key:
            logger.error("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
            
        # ãƒã‚¹ã‚¯ã—ã¦è¡¨ç¤º
        masked_key = f"{self.api_key[:8]}...{self.api_key[-4:]}"
        logger.info(f"âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™: {masked_key}")
        return True
        
    async def test_basic_connection(self) -> bool:
        """åŸºæœ¬çš„ãªAPIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸŒ åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ")
        logger.info("=" * 60)
        
        try:
            client = AsyncOpenAI(api_key=self.api_key)
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            start_time = time.time()
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": "Hello, this is a test. Reply with 'OK'."}],
                max_tokens=10,
                temperature=0
            )
            elapsed = time.time() - start_time
            
            reply = response.choices[0].message.content
            logger.info(f"âœ… APIæ¥ç¶šæˆåŠŸ")
            logger.info(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {reply}")
            logger.info(f"   å¿œç­”æ™‚é–“: {elapsed:.2f}ç§’")
            
            self.test_results['basic_connection'] = {
                'status': 'success',
                'response_time': elapsed,
                'response': reply
            }
            return True
            
        except Exception as e:
            logger.error(f"âŒ APIæ¥ç¶šå¤±æ•—: {str(e)}")
            self.test_results['basic_connection'] = {
                'status': 'failed',
                'error': str(e)
            }
            return False
            
    async def test_model_availability(self) -> Dict[str, bool]:
        """å„ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ¤– ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆ")
        logger.info("=" * 60)
        
        models_to_test = {
            "gpt-4o": "GPT-4o (Deep thinking)",
            "gpt-4o-mini": "GPT-4o-mini (Quick thinking)",
            "o3": "O3 (Advanced reasoning)",
            "o4-mini": "O4-mini (Fast reasoning)",
            "gpt-4-turbo": "GPT-4 Turbo",
            "gpt-3.5-turbo": "GPT-3.5 Turbo"
        }
        
        results = {}
        client = AsyncOpenAI(api_key=self.api_key)
        
        for model_id, model_name in models_to_test.items():
            logger.info(f"\nğŸ“ ãƒ†ã‚¹ãƒˆä¸­: {model_name} ({model_id})")
            
            try:
                start_time = time.time()
                
                # o3/o4ãƒ¢ãƒ‡ãƒ«ã®ç‰¹åˆ¥ãªè¨­å®š
                if model_id.startswith(('o3', 'o4')):
                    response = await client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "user", "content": "Test connection. Reply with model name."}],
                        max_completion_tokens=50,  # o-seriesã¯max_completion_tokens
                        temperature=1.0  # o-seriesã¯1.0å›ºå®š
                    )
                else:
                    response = await client.chat.completions.create(
                        model=model_id,
                        messages=[{"role": "user", "content": "Test connection. Reply with model name."}],
                        max_tokens=50,
                        temperature=0
                    )
                
                elapsed = time.time() - start_time
                reply = response.choices[0].message.content
                
                logger.info(f"   âœ… åˆ©ç”¨å¯èƒ½")
                logger.info(f"   å¿œç­”æ™‚é–“: {elapsed:.2f}ç§’")
                logger.info(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {reply[:100]}")
                
                results[model_id] = {
                    'available': True,
                    'response_time': elapsed,
                    'response': reply
                }
                
            except Exception as e:
                error_msg = str(e)
                if "model_not_found" in error_msg or "does not exist" in error_msg:
                    logger.warning(f"   âš ï¸  ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                else:
                    logger.error(f"   âŒ ã‚¨ãƒ©ãƒ¼: {error_msg[:100]}")
                    
                results[model_id] = {
                    'available': False,
                    'error': error_msg
                }
                
        self.test_results['model_availability'] = results
        return results
        
    async def test_langchain_integration(self) -> bool:
        """LangChainçµ±åˆã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ”— LangChainçµ±åˆãƒ†ã‚¹ãƒˆ")
        logger.info("=" * 60)
        
        try:
            # é€šå¸¸ã®ãƒ¢ãƒ‡ãƒ«
            logger.info("\nğŸ“ é€šå¸¸ãƒ¢ãƒ‡ãƒ« (gpt-4o-mini) ãƒ†ã‚¹ãƒˆ")
            llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0,
                max_tokens=50,
                timeout=30
            )
            
            messages = [
                SystemMessage(content="You are a helpful assistant."),
                HumanMessage(content="Reply with 'LangChain OK'")
            ]
            
            start_time = time.time()
            response = await llm.ainvoke(messages)
            elapsed = time.time() - start_time
            
            logger.info(f"   âœ… LangChainé€šå¸¸ãƒ¢ãƒ‡ãƒ«æ¥ç¶šæˆåŠŸ")
            logger.info(f"   å¿œç­”æ™‚é–“: {elapsed:.2f}ç§’")
            logger.info(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.content}")
            
            self.test_results['langchain_normal'] = {
                'status': 'success',
                'response_time': elapsed
            }
            
            # o-seriesãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            logger.info("\nğŸ“ O-seriesãƒ¢ãƒ‡ãƒ«äº’æ›æ€§ãƒ†ã‚¹ãƒˆ")
            
            # o3ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã«ã¯ä½¿ã‚ãªã„ï¼‰
            try:
                o_series_llm = ChatOpenAI(
                    model="gpt-4o",  # o3ã®ä»£ã‚ã‚Šã«gpt-4oã‚’ä½¿ç”¨
                    temperature=1.0,
                    max_completion_tokens=50,
                    timeout=60
                )
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ï¼ˆo-seriesã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
                o_messages = [
                    HumanMessage(content="Test o-series compatibility. Reply with 'OK'.")
                ]
                
                start_time = time.time()
                response = await o_series_llm.ainvoke(o_messages)
                elapsed = time.time() - start_time
                
                logger.info(f"   âœ… O-seriesäº’æ›è¨­å®šã§æ¥ç¶šæˆåŠŸ")
                logger.info(f"   å¿œç­”æ™‚é–“: {elapsed:.2f}ç§’")
                
                self.test_results['langchain_o_series'] = {
                    'status': 'success',
                    'response_time': elapsed
                }
                
            except Exception as e:
                logger.warning(f"   âš ï¸  O-seriesäº’æ›ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
                self.test_results['langchain_o_series'] = {
                    'status': 'failed',
                    'error': str(e)
                }
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ LangChainçµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
            self.test_results['langchain_integration'] = {
                'status': 'failed',
                'error': str(e)
            }
            return False
            
    async def test_json_response(self) -> bool:
        """JSONå½¢å¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ JSONå½¢å¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
        logger.info("=" * 60)
        
        try:
            client = AsyncOpenAI(api_key=self.api_key)
            
            prompt = """
            Please respond with a JSON object containing:
            - action: "BUY", "SELL", or "HOLD"
            - confidence: a number between 0 and 1
            - reason: a brief explanation
            
            Example format:
            {"action": "HOLD", "confidence": 0.7, "reason": "Market conditions unclear"}
            """
            
            start_time = time.time()
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0,
                response_format={"type": "json_object"}  # JSON mode
            )
            elapsed = time.time() - start_time
            
            reply = response.choices[0].message.content
            logger.info(f"âœ… JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—æˆåŠŸ")
            logger.info(f"   å¿œç­”æ™‚é–“: {elapsed:.2f}ç§’")
            
            # JSONãƒ‘ãƒ¼ã‚¹ç¢ºèª
            parsed_json = json.loads(reply)
            logger.info(f"   ãƒ‘ãƒ¼ã‚¹æˆåŠŸ: {json.dumps(parsed_json, ensure_ascii=False)}")
            
            self.test_results['json_response'] = {
                'status': 'success',
                'response_time': elapsed,
                'parsed_json': parsed_json
            }
            return True
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {reply}")
            self.test_results['json_response'] = {
                'status': 'parse_error',
                'error': str(e)
            }
            return False
            
        except Exception as e:
            logger.error(f"âŒ JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
            self.test_results['json_response'] = {
                'status': 'failed',
                'error': str(e)
            }
            return False
            
    async def test_concurrent_requests(self) -> bool:
        """ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸš€ ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ")
        logger.info("=" * 60)
        
        try:
            client = AsyncOpenAI(api_key=self.api_key)
            
            async def make_request(index: int):
                start = time.time()
                response = await client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": f"Test request {index}. Reply with the number."}],
                    max_tokens=10,
                    temperature=0
                )
                elapsed = time.time() - start
                return index, elapsed, response.choices[0].message.content
            
            # 5ã¤ã®ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            logger.info("   5ã¤ã®ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
            start_time = time.time()
            tasks = [make_request(i) for i in range(5)]
            results = await asyncio.gather(*tasks)
            total_time = time.time() - start_time
            
            logger.info(f"âœ… ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†")
            logger.info(f"   ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
            
            for index, elapsed, response in results:
                logger.info(f"   ãƒªã‚¯ã‚¨ã‚¹ãƒˆ{index}: {elapsed:.2f}ç§’ - {response}")
                
            self.test_results['concurrent_requests'] = {
                'status': 'success',
                'total_time': total_time,
                'request_count': len(results)
            }
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
            self.test_results['concurrent_requests'] = {
                'status': 'failed',
                'error': str(e)
            }
            return False
            
    def print_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 60)
        
        # åŸºæœ¬æ¥ç¶š
        if 'basic_connection' in self.test_results:
            status = self.test_results['basic_connection']['status']
            if status == 'success':
                logger.info("âœ… åŸºæœ¬æ¥ç¶š: æˆåŠŸ")
            else:
                logger.info("âŒ åŸºæœ¬æ¥ç¶š: å¤±æ•—")
                
        # ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½æ€§
        if 'model_availability' in self.test_results:
            models = self.test_results['model_availability']
            available = [m for m, r in models.items() if r['available']]
            unavailable = [m for m, r in models.items() if not r['available']]
            
            logger.info(f"\nğŸ“ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ« ({len(available)}å€‹):")
            for model in available:
                logger.info(f"   âœ… {model}")
                
            if unavailable:
                logger.info(f"\nğŸ“ åˆ©ç”¨ä¸å¯ã®ãƒ¢ãƒ‡ãƒ« ({len(unavailable)}å€‹):")
                for model in unavailable:
                    logger.info(f"   âŒ {model}")
                    
        # æ¨å¥¨è¨­å®š
        logger.info("\nğŸ’¡ æ¨å¥¨è¨­å®š:")
        if 'gpt-4o' in available:
            logger.info("   Deep Think Model: gpt-4o")
        if 'gpt-4o-mini' in available:
            logger.info("   Quick Think Model: gpt-4o-mini")
            
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        result_file = "api_test_results.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        logger.info(f"\nğŸ“ è©³ç´°ãªçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {result_file}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    tester = APIConnectionTester()
    
    # APIã‚­ãƒ¼ç¢ºèª
    if not tester.check_api_key():
        logger.error("\nâš ï¸  APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
        logger.error("export OPENAI_API_KEY='your-api-key-here'")
        return
        
    # å„ç¨®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    await tester.test_basic_connection()
    await tester.test_model_availability()
    await tester.test_langchain_integration()
    await tester.test_json_response()
    await tester.test_concurrent_requests()
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    tester.print_summary()
    
    logger.info("\nâœ… APIç–é€šãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ
    asyncio.run(main())