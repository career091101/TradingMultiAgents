#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«ãªOpenAI APIç–é€šãƒ†ã‚¹ãƒˆï¼ˆ.envå¯¾å¿œç‰ˆï¼‰
- åŸºæœ¬çš„ãªæ¥ç¶šç¢ºèª
- ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ç¢ºèª
"""

import os
import asyncio
import json
import time
from datetime import datetime
import logging
from pathlib import Path

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
def load_env():
    env_file = Path('.env')
    if env_file.exists():
        with open(env_file) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value

# .envã‚’èª­ã¿è¾¼ã‚€
load_env()

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_openai_connection():
    """OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆç´”ç²‹ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆç‰ˆï¼‰"""
    
    logger.info("=" * 60)
    logger.info("ğŸ”‘ OpenAI API ç–é€šãƒ†ã‚¹ãƒˆ")
    logger.info("=" * 60)
    
    # APIã‚­ãƒ¼ç¢ºèª
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        logger.error("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        logger.error("è¨­å®šæ–¹æ³•: export OPENAI_API_KEY='your-api-key-here'")
        return
        
    masked_key = f"{api_key[:8]}...{api_key[-4:]}"
    logger.info(f"âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™: {masked_key}")
    
    # aiohttp ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        import aiohttp
    except ImportError:
        logger.error("âŒ aiohttpãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        logger.error("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install aiohttp")
        return
        
    # ãƒ†ã‚¹ãƒˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«
    models_to_test = [
        ("gpt-4o-mini", "GPT-4o-mini (Quick thinking)"),
        ("gpt-4o", "GPT-4o (Deep thinking)"), 
        ("gpt-3.5-turbo", "GPT-3.5 Turbo"),
        ("gpt-4-turbo", "GPT-4 Turbo"),
    ]
    
    logger.info("\nğŸ“ ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆ")
    logger.info("-" * 40)
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    async with aiohttp.ClientSession() as session:
        available_models = []
        
        for model_id, model_name in models_to_test:
            logger.info(f"\nãƒ†ã‚¹ãƒˆä¸­: {model_name} ({model_id})")
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
            payload = {
                "model": model_id,
                "messages": [{"role": "user", "content": "Test. Reply with 'OK'."}],
                "max_tokens": 10,
                "temperature": 0
            }
            
            try:
                start_time = time.time()
                
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    elapsed = time.time() - start_time
                    
                    if response.status == 200:
                        data = await response.json()
                        reply = data['choices'][0]['message']['content']
                        logger.info(f"   âœ… åˆ©ç”¨å¯èƒ½")
                        logger.info(f"   å¿œç­”æ™‚é–“: {elapsed:.2f}ç§’")
                        logger.info(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {reply}")
                        available_models.append(model_id)
                        
                    else:
                        error_text = await response.text()
                        error_data = json.loads(error_text) if error_text else {}
                        error_msg = error_data.get('error', {}).get('message', 'Unknown error')
                        
                        if "model_not_found" in error_msg or "does not exist" in error_msg:
                            logger.warning(f"   âš ï¸  ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        else:
                            logger.error(f"   âŒ ã‚¨ãƒ©ãƒ¼: {error_msg}")
                            
            except asyncio.TimeoutError:
                logger.error(f"   âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (30ç§’)")
            except Exception as e:
                logger.error(f"   âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                
    # ã‚µãƒãƒªãƒ¼
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    logger.info("=" * 60)
    
    if available_models:
        logger.info(f"\nâœ… åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ« ({len(available_models)}å€‹):")
        for model in available_models:
            logger.info(f"   - {model}")
            
        logger.info("\nğŸ’¡ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ¨å¥¨è¨­å®š:")
        logger.info("   å®Ÿéš›ã®LLMã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ:")
        if "gpt-4o" in available_models:
            logger.info("     Deep Think Model: gpt-4o")
        elif "gpt-4-turbo" in available_models:
            logger.info("     Deep Think Model: gpt-4-turbo")
            
        if "gpt-4o-mini" in available_models:
            logger.info("     Quick Think Model: gpt-4o-mini")
        elif "gpt-3.5-turbo" in available_models:
            logger.info("     Quick Think Model: gpt-3.5-turbo")
            
        logger.info("\n   ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ:")
        logger.info("     Deep Think Model: mock")
        logger.info("     Quick Think Model: mock")
            
    else:
        logger.error("\nâŒ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        logger.error("APIã‚­ãƒ¼ã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
    # JSONå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    if available_models:
        logger.info("\nğŸ“‹ JSONå½¢å¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
        logger.info("-" * 40)
        
        test_model = available_models[0]
        logger.info(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {test_model}")
        
        json_prompt = """Please respond with JSON format:
{
  "action": "HOLD",
  "confidence": 0.7,
  "reason": "Test response"
}"""
        
        payload = {
            "model": test_model,
            "messages": [{"role": "user", "content": json_prompt}],
            "max_tokens": 100,
            "temperature": 0
        }
        
        if test_model in ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo"]:
            payload["response_format"] = {"type": "json_object"}
            
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        reply = data['choices'][0]['message']['content']
                        
                        # JSONãƒ‘ãƒ¼ã‚¹è©¦è¡Œ
                        try:
                            parsed = json.loads(reply)
                            logger.info("   âœ… JSONå½¢å¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹æˆåŠŸ")
                            logger.info(f"   ãƒ‘ãƒ¼ã‚¹çµæœ: {json.dumps(parsed, ensure_ascii=False)}")
                        except json.JSONDecodeError:
                            logger.warning("   âš ï¸  JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—")
                            logger.info(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {reply}")
                            
        except Exception as e:
            logger.error(f"   âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
    # ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ
    if available_models:
        logger.info("\nğŸš€ ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ")
        logger.info("-" * 40)
        
        test_model = available_models[0]
        logger.info(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {test_model}")
        logger.info("3ã¤ã®ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡...")
        
        async def make_request(session, index):
            start = time.time()
            payload = {
                "model": test_model,
                "messages": [{"role": "user", "content": f"Request {index}. Reply with the number."}],
                "max_tokens": 10,
                "temperature": 0
            }
            
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    reply = data['choices'][0]['message']['content']
                    elapsed = time.time() - start
                    return index, elapsed, reply
                else:
                    return index, 0, "Error"
                    
        try:
            async with aiohttp.ClientSession() as session:
                start_total = time.time()
                results = await asyncio.gather(
                    make_request(session, 1),
                    make_request(session, 2),
                    make_request(session, 3)
                )
                total_time = time.time() - start_total
                
                logger.info(f"   âœ… ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†")
                logger.info(f"   ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
                
                for index, elapsed, reply in results:
                    logger.info(f"   ãƒªã‚¯ã‚¨ã‚¹ãƒˆ{index}: {elapsed:.2f}ç§’ - {reply}")
                    
        except Exception as e:
            logger.error(f"   âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
    logger.info("\nâœ… APIç–é€šãƒ†ã‚¹ãƒˆå®Œäº†")
    
    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    test_results = {
        "timestamp": datetime.now().isoformat(),
        "api_key_masked": masked_key if api_key else None,
        "available_models": available_models,
        "recommended_settings": {
            "with_llm": {
                "deep_think_model": "gpt-4o" if "gpt-4o" in available_models else "gpt-4-turbo",
                "quick_think_model": "gpt-4o-mini" if "gpt-4o-mini" in available_models else "gpt-3.5-turbo"
            },
            "mock_mode": {
                "deep_think_model": "mock",
                "quick_think_model": "mock"
            }
        }
    }
    
    with open("api_test_results.json", "w", encoding="utf-8") as f:
        json.dump(test_results, f, ensure_ascii=False, indent=2)
    logger.info(f"\nğŸ“ ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: api_test_results.json")


if __name__ == "__main__":
    # åŸºæœ¬çš„ãªæ¥ç¶šãƒ†ã‚¹ãƒˆ
    asyncio.run(test_openai_connection())